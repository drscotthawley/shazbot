{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e74217ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp blocks_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7bea519",
   "metadata": {},
   "source": [
    "# blocks_utils\n",
    "\n",
    "> Utils from https://github.com/zqevans/audio-diffusion/blob/main/blocks/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6311da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "from contextlib import contextmanager\n",
    "import warnings\n",
    "\n",
    "import torch\n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b390e7b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def append_dims(x, target_dims):\n",
    "    \"\"\"Appends dimensions to the end of a tensor until it has target_dims dimensions.\"\"\"\n",
    "    dims_to_append = target_dims - x.ndim\n",
    "    if dims_to_append < 0:\n",
    "        raise ValueError(f'input has {x.ndim} dims but target_dims is {target_dims}, which is less')\n",
    "    return x[(...,) + (None,) * dims_to_append]\n",
    "\n",
    "\n",
    "def n_params(module):\n",
    "    \"\"\"Returns the number of trainable parameters in a module.\"\"\"\n",
    "    return sum(p.numel() for p in module.parameters())\n",
    "\n",
    "\n",
    "@contextmanager\n",
    "def train_mode(model, mode=True):\n",
    "    \"\"\"A context manager that places a model into training mode and restores\n",
    "    the previous mode on exit.\"\"\"\n",
    "    modes = [module.training for module in model.modules()]\n",
    "    try:\n",
    "        yield model.train(mode)\n",
    "    finally:\n",
    "        for i, module in enumerate(model.modules()):\n",
    "            module.training = modes[i]\n",
    "\n",
    "\n",
    "def eval_mode(model):\n",
    "    \"\"\"A context manager that places a model into evaluation mode and restores\n",
    "    the previous mode on exit.\"\"\"\n",
    "    return train_mode(model, False)\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def ema_update(model, averaged_model, decay):\n",
    "    \"\"\"Incorporates updated model parameters into an exponential moving averaged\n",
    "    version of a model. It should be called after each optimizer step.\"\"\"\n",
    "    model_params = dict(model.named_parameters())\n",
    "    averaged_params = dict(averaged_model.named_parameters())\n",
    "    assert model_params.keys() == averaged_params.keys()\n",
    "\n",
    "    for name, param in model_params.items():\n",
    "        averaged_params[name].mul_(decay).add_(param, alpha=1 - decay)\n",
    "\n",
    "    model_buffers = dict(model.named_buffers())\n",
    "    averaged_buffers = dict(averaged_model.named_buffers())\n",
    "    assert model_buffers.keys() == averaged_buffers.keys()\n",
    "\n",
    "    for name, buf in model_buffers.items():\n",
    "        averaged_buffers[name].copy_(buf)\n",
    "\n",
    "\n",
    "class EMAWarmup:\n",
    "    \"\"\"Implements an EMA warmup using an inverse decay schedule.\n",
    "    If inv_gamma=1 and power=1, implements a simple average. inv_gamma=1, power=2/3 are\n",
    "    good values for models you plan to train for a million or more steps (reaches decay\n",
    "    factor 0.999 at 31.6K steps, 0.9999 at 1M steps), inv_gamma=1, power=3/4 for models\n",
    "    you plan to train for less (reaches decay factor 0.999 at 10K steps, 0.9999 at\n",
    "    215.4k steps).\n",
    "    Args:\n",
    "        inv_gamma (float): Inverse multiplicative factor of EMA warmup. Default: 1.\n",
    "        power (float): Exponential factor of EMA warmup. Default: 1.\n",
    "        min_value (float): The minimum EMA decay rate. Default: 0.\n",
    "        max_value (float): The maximum EMA decay rate. Default: 1.\n",
    "        start_at (int): The epoch to start averaging at. Default: 0.\n",
    "        last_epoch (int): The index of last epoch. Default: 0.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, inv_gamma=1., power=1., min_value=0., max_value=1., start_at=0,\n",
    "                 last_epoch=0):\n",
    "        self.inv_gamma = inv_gamma\n",
    "        self.power = power\n",
    "        self.min_value = min_value\n",
    "        self.max_value = max_value\n",
    "        self.start_at = start_at\n",
    "        self.last_epoch = last_epoch\n",
    "\n",
    "    def state_dict(self):\n",
    "        \"\"\"Returns the state of the class as a :class:`dict`.\"\"\"\n",
    "        return dict(self.__dict__.items())\n",
    "\n",
    "    def load_state_dict(self, state_dict):\n",
    "        \"\"\"Loads the class's state.\n",
    "        Args:\n",
    "            state_dict (dict): scaler state. Should be an object returned\n",
    "                from a call to :meth:`state_dict`.\n",
    "        \"\"\"\n",
    "        self.__dict__.update(state_dict)\n",
    "\n",
    "    def get_value(self):\n",
    "        \"\"\"Gets the current EMA decay rate.\"\"\"\n",
    "        epoch = max(0, self.last_epoch - self.start_at)\n",
    "        value = 1 - (1 + epoch / self.inv_gamma) ** -self.power\n",
    "        return 0. if epoch < 0 else min(self.max_value, max(self.min_value, value))\n",
    "\n",
    "    def step(self):\n",
    "        \"\"\"Updates the step count.\"\"\"\n",
    "        self.last_epoch += 1\n",
    "\n",
    "\n",
    "class InverseLR(optim.lr_scheduler._LRScheduler):\n",
    "    \"\"\"Implements an inverse decay learning rate schedule with an optional exponential\n",
    "    warmup. When last_epoch=-1, sets initial lr as lr.\n",
    "    inv_gamma is the number of steps/epochs required for the learning rate to decay to\n",
    "    (1 / 2)**power of its original value.\n",
    "    Args:\n",
    "        optimizer (Optimizer): Wrapped optimizer.\n",
    "        inv_gamma (float): Inverse multiplicative factor of learning rate decay. Default: 1.\n",
    "        power (float): Exponential factor of learning rate decay. Default: 1.\n",
    "        warmup (float): Exponential warmup factor (0 <= warmup < 1, 0 to disable)\n",
    "            Default: 0.\n",
    "        final_lr (float): The final learning rate. Default: 0.\n",
    "        last_epoch (int): The index of last epoch. Default: -1.\n",
    "        verbose (bool): If ``True``, prints a message to stdout for\n",
    "            each update. Default: ``False``.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, optimizer, inv_gamma=1., power=1., warmup=0., final_lr=0.,\n",
    "                 last_epoch=-1, verbose=False):\n",
    "        self.inv_gamma = inv_gamma\n",
    "        self.power = power\n",
    "        if not 0. <= warmup < 1:\n",
    "            raise ValueError('Invalid value for warmup')\n",
    "        self.warmup = warmup\n",
    "        self.final_lr = final_lr\n",
    "        super().__init__(optimizer, last_epoch, verbose)\n",
    "\n",
    "    def get_lr(self):\n",
    "        if not self._get_lr_called_within_step:\n",
    "            warnings.warn(\"To get the last learning rate computed by the scheduler, \"\n",
    "                          \"please use `get_last_lr()`.\")\n",
    "\n",
    "        return self._get_closed_form_lr()\n",
    "\n",
    "    def _get_closed_form_lr(self):\n",
    "        warmup = 1 - self.warmup ** (self.last_epoch + 1)\n",
    "        lr_mult = (1 + self.last_epoch / self.inv_gamma) ** -self.power\n",
    "        return [warmup * max(self.final_lr, base_lr * lr_mult)\n",
    "                for base_lr in self.base_lrs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa610c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
