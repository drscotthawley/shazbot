{
 "cells": [
  {
   "cell_type": "raw",
   "id": "0fc3bd65",
   "metadata": {},
   "source": [
    "---\n",
    "skip_showdoc: true\n",
    "skip_exec: true\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc33d664",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp icebox"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a963eebd",
   "metadata": {},
   "source": [
    "# icebox\n",
    "> Routines for working with frozen jukebox embeddings\n",
    "\n",
    "Combination of TagBox repo by Ethan Manilow et al plus additions/modifications by Scott Hawley.\n",
    "\n",
    "This can be used as a library to be called from elsewhere, or as its own standalone script (mostly for testing and evaluation). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ba33ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "import torch \n",
    "from torch import nn \n",
    "from torch import multiprocessing as mp\n",
    "import torch.distributed as dist\n",
    "from torch.nn import functional as F\n",
    "import torchaudio\n",
    "from jukebox.make_models import make_vqvae, make_prior, MODELS, make_model\n",
    "from jukebox.hparams import Hyperparams, setup_hparams\n",
    "import os\n",
    "import accelerate\n",
    "from aeiou.hpc import get_accel_config, HostPrinter\n",
    "from aeiou.viz import embeddings_table, pca_point_cloud, audio_spectrogram_image, tokens_spectrogram_image, plot_jukebox_embeddings\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1866ac21",
   "metadata": {},
   "source": [
    "## TagBox utils\n",
    "\n",
    "Utilities from Ethan Manilows's TagBox: https://github.com/ethman/tagbox, slightly modified by Scott H. Hawley @drscotthawley\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffca9e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export \n",
    "\n",
    "#JUKEBOX_SAMPLE_RATE = 44100  # ethan's original\n",
    "JUKEBOX_SAMPLE_RATE = None\n",
    "\n",
    "def init_jukebox_sample_rate(\n",
    "    sr=44100  # sample rate in Hz. OpenAI's pretrained Jukebox weights are for 44100\n",
    "    ): \n",
    "    \"SHH added this util to preserve rest of code minimall-modified\"\n",
    "    global JUKEBOX_SAMPLE_RATE\n",
    "    JUKEBOX_SAMPLE_RATE = sr\n",
    "    return\n",
    "\n",
    "def stereo(signal):\n",
    "    signal_shape = signal.shape\n",
    "    if len(signal_shape) == 1: # s -> 2, s\n",
    "        signal = signal.unsqueeze(0).repeat(2, 1)\n",
    "    elif len(signal_shape) == 2:\n",
    "        if signal_shape[0] == 1: #1, s -> 2, s\n",
    "            signal = signal.repeat(2, 1)\n",
    "        elif signal_shape[0] > 2: #?, s -> 2,s\n",
    "            signal = signal[:2, :]  \n",
    "    return signal \n",
    "\n",
    "def audio_for_jbx(audio, trunc_sec=None, device=None):\n",
    "    \"\"\"Readies an audio TENSOR for Jukebox.\"\"\"\n",
    "    if audio.ndim == 1:\n",
    "        audio = audio[None]\n",
    "        audio = audio.mean(axis=0)\n",
    "    #print(\"1 audio.shape = \",audio.shape)\n",
    "\n",
    "    # normalize audio\n",
    "    norm_factor = torch.abs(audio).max()\n",
    "    if norm_factor > 0:\n",
    "        audio /= norm_factor\n",
    "\n",
    "    if trunc_sec is not None:  # truncate sequence\n",
    "        audio = audio[: int(JUKEBOX_SAMPLE_RATE * trunc_sec)]\n",
    "\n",
    "    audio = torch.unsqueeze(audio, 0)  # batch dimension\n",
    "    audio = torch.unsqueeze(audio, dim=-1)  # another dimension ?\n",
    "    return audio\n",
    "\n",
    "\n",
    "def load_audio_for_jbx(path, offset=0.0, dur=None, trunc_sec=None, device=None):\n",
    "    \"\"\"Loads a path for use with Jukebox.\"\"\"\n",
    "    audio, sr = librosa.load(path, sr=None, offset=offset, duration=dur)\n",
    "\n",
    "    if JUKEBOX_SAMPLE_RATE is None: init_jukebox_sample_rate()\n",
    "\n",
    "    if sr != JUKEBOX_SAMPLE_RATE:\n",
    "        audio = librosa.resample(audio, sr, JUKEBOX_SAMPLE_RATE)\n",
    "    audio = torch.from_numpy(audio)\n",
    "    #print(\"0, audio.shape = \",audio.shape)\n",
    "    return audio_for_jbx(audio, trunc_sec, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8870d4dd",
   "metadata": {},
   "source": [
    "## Icebox Encoder\n",
    "frozen Jukebox encoder for embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb9a0d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class IceBoxModel(nn.Module):\n",
    "    def __init__(self, global_args, device, port=9500):\n",
    "        super().__init__()\n",
    "\n",
    "        n_io_channels = 2\n",
    "        n_feature_channels = 8\n",
    "\n",
    "        # for making Jukebox work with multi-GPU runs\n",
    "        rank = global_args.rank\n",
    "        #local_rank, device = int(os.getenv('RANK')), int(os.getenv('LOCAL_RANK')), device\n",
    "\n",
    "        # torch.distributed info set at top-level training script\n",
    "        #dist_url = f\"tcp://127.0.0.1:{port}\"  # Note port may differ on different machines\n",
    "        #dist.init_process_group(backend=\"nccl\")\n",
    "\n",
    "        self.hps = Hyperparams()\n",
    "        assert global_args.sample_rate == 44100, \"Jukebox was pretrained at 44100 Hz.\"\n",
    "        self.hps.sr = global_args.sample_rate #44100\n",
    "        self.hps.levels = 3\n",
    "        self.hps.hop_fraction = [.5,.5,.125]\n",
    "\n",
    "        vqvae = \"vqvae\"\n",
    "        self.vqvae = make_vqvae(setup_hparams(vqvae, dict(sample_length = 1048576)), device)\n",
    "        for param in self.vqvae.parameters():  # FREEZE IT.  \"IceBox\"\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        self.dummy = nn.Linear(1,1) # just to allow DistributedDataParallel\n",
    "\n",
    "        self.encoder = self.vqvae.encode\n",
    "        self.decoder = self.vqvae.decode\n",
    "\n",
    "        latent_dim = 64 # global_args.latent_dim. Jukebox is 64\n",
    "        io_channels = 2#1 # 2.  Jukebox is mono but we decode in stereo\n",
    " \n",
    "    def encode(self, *args, **kwargs):\n",
    "        return self.encoder(*args, **kwargs)\n",
    "\n",
    "    def decode(self, *args, **kwargs):\n",
    "        return self.decoder(*args, **kwargs)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d97831f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def batch_it_crazy(x, win_len):\n",
    "    \"(pun intended) Chop up long sequence into a batch of win_len windows\"\n",
    "    x_len = x.size()[-1]\n",
    "    n_windows = (x_len // win_len) + 1\n",
    "    pad_amt = win_len * n_windows - x_len  # pad end w. zeros to make lengths even when split\n",
    "    xpad = F.pad(x, (0, pad_amt))\n",
    "    return rearrange(xpad, 'd (b n) -> b d n', n=win_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80da5eef",
   "metadata": {},
   "source": [
    "## Main execution \n",
    "this is really intended for brief testing, e.g. to ensure the various parts work.\n",
    " see elsewhere for a full run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bc5fd64",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| slow\n",
    "#|export\n",
    "def main():\n",
    "    #from dotmap import DotMap  # only used for setting some args\n",
    "    from prefigure.prefigure import get_all_args, push_wandb_config\n",
    "\n",
    "    try:\n",
    "        args = get_all_args()\n",
    "    except:\n",
    "        print(\"Can't read config file. Exiting\")\n",
    "        return \n",
    "        \n",
    "    torch.manual_seed(args.seed)\n",
    "\n",
    "    try:\n",
    "        mp.set_start_method(args.start_method)\n",
    "    except RuntimeError:\n",
    "        pass\n",
    "\n",
    "    accelerator = accelerate.Accelerator()\n",
    "    device = accelerator.device\n",
    "    hprint = HostPrinter(accelerator)\n",
    "    hprint(f\"device = {device}\")\n",
    "    hprint(f\"accelerator = {accelerator}\")\n",
    "    ac = get_accel_config()\n",
    "    hprint(f\"ac = {ac}\")\n",
    "    port = ac['main_process_port']\n",
    "    #args = DotMap()\n",
    "    args.name = 'icebox-test'\n",
    "    args.sample_rate = 44100\n",
    "    args.rank = ac['machine_rank']\n",
    "    os.environ[\"RANK\"] = str(args.rank)\n",
    "    if device != 'cpu':\n",
    "        icebox = IceBoxModel(args, device, port=port)\n",
    "        hprint(\"IceBoxModel config finished!\")\n",
    "    else:\n",
    "        print(\"can't start up icebox because no GPUs are available.\")\n",
    "\n",
    "    icebox = accelerator.prepare(icebox)\n",
    "\n",
    "    hprint(f\"Loading audio\")\n",
    "    input_filename = 'test_audio.wav'\n",
    "    input_audio = load_audio_for_jbx(input_filename).to(device)\n",
    "    #demo_reals = batch_it_crazy(input_audio, args.sample_size)\n",
    "\n",
    "\n",
    "    hprint(f\"Encoding audio\")\n",
    "    with torch.cuda.amp.autocast():\n",
    "        zs = accelerator.unwrap_model(icebox).encode(input_audio)\n",
    "        hprint(f\"  len(zs) = {len(zs)}\")\n",
    "        for i, z in enumerate(zs):\n",
    "            hprint(f\"  zs[{i}].shape = {z.shape}\")\n",
    "\n",
    "    hprint(f\"Decoding audio\")\n",
    "    decoded = accelerator.unwrap_model(icebox).decode(zs).transpose(-2, -1)\n",
    "    hprint(f\"  decoded.shape = {decoded.shape}\")\n",
    "    output_audio = torch.squeeze(decoded, dim=0).cpu() \n",
    "    #output_audio *=  0.2 # it's too loud for some reason\n",
    "    hprint(f\"  output_audio.shape = {output_audio.shape}\")\n",
    "    output_filename = 'test_audio_out.wav'\n",
    "\n",
    "    hprint(f\"Saving output audio {output_filename}...\")\n",
    "    torchaudio.save(output_filename, output_audio, args.sample_rate)\n",
    "\n",
    "    input_audio = torch.squeeze(input_audio, dim=-1).cpu()\n",
    "    hprint(f\"input_audio.shape = {input_audio.shape}\")\n",
    "\n",
    "    use_wandb = accelerator.is_main_process and args.name\n",
    "    if use_wandb:\n",
    "        import wandb\n",
    "        hprint(\"Now sending to WandB\")\n",
    "        config = vars(args)\n",
    "        wandb.init(project=args.name, config=config, save_code=True)\n",
    "        log_dict = {}\n",
    "\n",
    "        log_dict['input_audio']  = wandb.Audio(input_filename, sample_rate=args.sample_rate, caption='input_audio')\n",
    "        log_dict['output_audio'] = wandb.Audio(output_filename, sample_rate=args.sample_rate, caption='output_audio')\n",
    "        log_dict[f'input_melspec_left'] = wandb.Image(audio_spectrogram_image(input_audio, print=hprint))\n",
    "        log_dict[f'output_melspec_left'] = wandb.Image(audio_spectrogram_image(output_audio, print=hprint))\n",
    "\n",
    "        if False:\n",
    "            hprint(\"Logging embeddings...\")\n",
    "            log_dict[f'zplots'] = wandb.log(plot_jukebox_embeddings(zs))\n",
    "            #log_dict[f'zplots2'] = wandb.Image(plot_jukebox_embeddings(zs))\n",
    "\n",
    "        # make a 3d cube of jukebox embeddings\n",
    "        em_plot_arr =torch.zeros((3,zs[0].shape[-1]))\n",
    "        em_plot_arr[0,:] = zs[0][0]\n",
    "        em_plot_arr[1,:] = zs[1][0].repeat(4)\n",
    "        em_plot_arr[2,:-4] = zs[2][0].repeat(4*4)\n",
    "        absmax = torch.max(torch.abs(em_plot_arr))\n",
    "        em_plot_arr = (em_plot_arr - em_plot_arr.mean()) / absmax # normalize a bit\n",
    "        log_dict[f'emb_3d_color=time'] = pca_point_cloud(em_plot_arr.unsqueeze(0), color_scheme='n')\n",
    "\n",
    "        hprint(f\"log_dict = {log_dict}\")\n",
    "        wandb.log(log_dict, step=0)\n",
    "\n",
    "    hprint(\"\\n--------------------\\nFinished!\\n-------------\")\n",
    "    \n",
    "if __name__ == '__main__':  # often this will only be called for testing\n",
    "    main() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bae18e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
