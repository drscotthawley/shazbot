{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b703b37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9414fc4",
   "metadata": {},
   "source": [
    "# data\n",
    "> Routines for loading/handling data\n",
    "\n",
    "Many of these routines are dupes or mods from \"audio-diffusion\" repo by Zach Evans w/ contributions by Scott Hawley https://github.com/zqevans/audio-diffusion/blob/main/diffusion/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb91a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchaudio\n",
    "from os import makedirs\n",
    "from torchaudio import transforms as T\n",
    "import random\n",
    "from glob import glob\n",
    "import os\n",
    "import tqdm\n",
    "from multiprocessing import Pool, cpu_count, Barrier\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79380ec",
   "metadata": {},
   "source": [
    "## Augmentation routines\n",
    "\n",
    "Not all of these are used.  Code copied from https://github.com/zqevans/audio-diffusion/blob/main/diffusion/utils.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6520c9bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "class PadCrop(nn.Module):\n",
    "    def __init__(self, n_samples, randomize=True):\n",
    "        super().__init__()\n",
    "        self.n_samples = n_samples\n",
    "        self.randomize = randomize\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        n, s = signal.shape\n",
    "        start = 0 if (not self.randomize) else torch.randint(0, max(0, s - self.n_samples) + 1, []).item()\n",
    "        end = start + self.n_samples\n",
    "        output = signal.new_zeros([n, self.n_samples])\n",
    "        output[:, :min(s, self.n_samples)] = signal[:, start:end]\n",
    "        return output\n",
    "\n",
    "    \n",
    "class PhaseFlipper(nn.Module):\n",
    "    \"she was PHAAAAAAA-AAAASE FLIPPER, a random invert yeah\"\n",
    "    def __init__(self, p=0.5):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def __call__(self, signal):\n",
    "        return -signal if (random.random() < self.p) else signal\n",
    "\n",
    "\n",
    "class FillTheNoise(nn.Module):\n",
    "    \"randomly adds a bit of noise, just to spice things up\"\n",
    "    def __init__(self, p=0.33):\n",
    "        super().__init__()\n",
    "        self.p = p\n",
    "    def __call__(self, signal):\n",
    "        return signal + 0.25*random.random()*(2*torch.rand_like(signal)-1) if (random.random() < self.p) else signal\n",
    "\n",
    "    \n",
    "class RandPool(nn.Module):\n",
    "    def __init__(self, p=0.2):\n",
    "        self.p, self.maxkern = p, 100\n",
    "    def __call__(self, signal):\n",
    "        if (random.random() < self.p):\n",
    "            ksize = int(random.random()*self.maxkern)\n",
    "            avger = nn.AvgPool1d(kernel_size=ksize, stride=1, padding=1)\n",
    "            return avger(signal)\n",
    "        else:\n",
    "            return signal\n",
    "        \n",
    "\n",
    "class NormInputs(nn.Module):\n",
    "    \"useful for quiet inputs. intended to be part of augmentation chain; not activated by default\"\n",
    "    def __init__(self, do_norm=False):\n",
    "        super().__init__()\n",
    "        self.do_norm = do_norm\n",
    "        self.eps = 1e-2\n",
    "    def __call__(self, signal):\n",
    "        return signal if (not self.do_norm) else signal/(torch.amax(signal,-1)[0] + self.eps)\n",
    "\n",
    "    \n",
    "class Mono(nn.Module):\n",
    "    def __call__(self, signal):\n",
    "        return torch.mean(signal, dim=0) if len(signal.shape) > 1 else signal\n",
    "\n",
    "\n",
    "class Stereo(nn.Module):\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        signal_shape = signal.shape\n",
    "        # Check if it's mono\n",
    "        if len(signal_shape) == 1: # s -> 2, s\n",
    "            signal = signal.unsqueeze(0).repeat(2, 1)\n",
    "        elif len(signal_shape) == 2:\n",
    "            if signal_shape[0] == 1: #1, s -> 2, s\n",
    "                signal = signal.repeat(2, 1)\n",
    "            elif signal_shape[0] > 2: #?, s -> 2,s\n",
    "                signal = signal[:2, :]    \n",
    "        return signal\n",
    "\n",
    "    \n",
    "class RandomGain(nn.Module):\n",
    "    def __init__(self, min_gain, max_gain):\n",
    "        super().__init__()\n",
    "        self.min_gain = min_gain\n",
    "        self.max_gain = max_gain\n",
    "\n",
    "    def __call__(self, signal):\n",
    "        gain = random.uniform(self.min_gain, self.max_gain)\n",
    "        signal = signal * gain\n",
    "        return signal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf846139",
   "metadata": {},
   "source": [
    "## Dataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ba890cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "# modified from https://github.com/drscotthawley/audio-diffusion/blob/main/dataset/dataset.py\n",
    "class MultiStemDataset(torch.utils.data.Dataset):\n",
    "  def __init__(self, paths, global_args):\n",
    "    super().__init__()\n",
    "    self.filenames = []\n",
    "    self.augs = torch.nn.Sequential(\n",
    "      PadCrop(global_args.sample_size, randomize=global_args.random_crop),\n",
    "      #RandomGain(0.7, 1.0),\n",
    "      #NormInputs(do_norm=global_args.norm_inputs),\n",
    "      #OneMinus(), # this is crazy, reverse the signal rel. to +/-1\n",
    "      #RandPool(),\n",
    "      #FillTheNoise(),\n",
    "      PhaseFlipper(),\n",
    "      #NormInputs(do_norm=global_args.norm_inputs),\n",
    "    )\n",
    "\n",
    "    self.encoding = torch.nn.Sequential(\n",
    "      Stereo()\n",
    "    )\n",
    "\n",
    "    for path in paths:   # get a list of relevant filenames\n",
    "      for ext in ['wav','flac','ogg','aiff','aif','mp3']:\n",
    "        self.filenames += glob(f'{path}/**/*.{ext}', recursive=True)\n",
    "\n",
    "    self.sr = global_args.sample_rate\n",
    "    if hasattr(global_args,'load_frac'):\n",
    "      self.load_frac = global_args.load_frac\n",
    "    else:\n",
    "      self.load_frac = 1.0\n",
    "    self.n_files = int(len(self.filenames)*self.load_frac)\n",
    "    self.filenames = self.filenames[0:self.n_files]\n",
    "    \n",
    "    self.num_gpus = global_args.num_gpus\n",
    "\n",
    "    self.cache_training_data = global_args.cache_training_data\n",
    "\n",
    "    if self.cache_training_data: self.preload_files()\n",
    "\n",
    "\n",
    "  def load_file(self, filename):\n",
    "    audio, sr = torchaudio.load(filename)\n",
    "    if sr != self.sr:\n",
    "      resample_tf = T.Resample(sr, self.sr)\n",
    "      audio = resample_tf(audio)\n",
    "    return audio\n",
    "\n",
    "  def load_file_ind(self, file_list,i): # used when caching training data\n",
    "    return self.load_file(file_list[i]).cpu()\n",
    "\n",
    "  def get_data_range(self): # for parallel runs, only grab part of the data\n",
    "    start, stop = 0, len(self.filenames)\n",
    "    try: \n",
    "      local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "      world_size = int(os.environ[\"WORLD_SIZE\"])\n",
    "      interval = stop//world_size \n",
    "      start, stop = local_rank*interval, (local_rank+1)*interval\n",
    "      #print(\"local_rank, world_size, start, stop =\",local_rank, world_size, start, stop)\n",
    "      return start, stop\n",
    "      #rank = os.environ[\"RANK\"]\n",
    "    except KeyError as e: # we're on GPU 0 and the others haven't been initialized yet\n",
    "      start, stop = 0, len(self.filenames)//self.num_gpus\n",
    "      return start, stop\n",
    "\n",
    "  def preload_files(self):\n",
    "      print(f\"Caching {self.n_files} input audio files:\")\n",
    "      wrapper = partial(self.load_file_ind, self.filenames)\n",
    "      start, stop = self.get_data_range()\n",
    "      with Pool(processes=cpu_count()) as p:   # //8 to avoid FS bottleneck and/or too many processes (b/c * num_gpus)\n",
    "        self.audio_files = list(tqdm.tqdm(p.imap(wrapper, range(start,stop)), total=stop-start))\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.filenames)\n",
    "\n",
    "  def __getitem__(self, idx):\n",
    "    audio_filename = self.filenames[idx]\n",
    "    try:\n",
    "      if self.cache_training_data:\n",
    "        audio = self.audio_files[idx] # .copy()\n",
    "      else:\n",
    "        audio = self.load_file(audio_filename)\n",
    "\n",
    "      #Run augmentations on this sample (including random crop)\n",
    "      if self.augs is not None:\n",
    "        audio = self.augs(audio)\n",
    "\n",
    "      audio = audio.clamp(-1, 1)\n",
    "\n",
    "      #Encode the file to assist in prediction\n",
    "      if self.encoding is not None:\n",
    "        audio = self.encoding(audio)\n",
    "\n",
    "      return (audio, audio_filename)\n",
    "    except Exception as e:\n",
    "     # print(f'Couldn\\'t load file {audio_filename}: {e}')\n",
    "      return self[random.randrange(len(self))]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
